{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from pytorchvideo.models.hub.slowfast import slowfast_16x8_r101_50_50\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False \n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "flags={}\n",
    "flags['batch_size'] = 2\n",
    "flags['num_worker'] = 0\n",
    "flags['learning_rate'] = 5e-5\n",
    "flags['epoch'] = 100\n",
    "flags['size'] = 256\n",
    "flags['mean'] = [0.45, 0.45, 0.45]\n",
    "flags['std'] = [0.225, 0.225, 0.225]\n",
    "flags['num_frames'] = 64\n",
    "flags['sampling_rate'] = 1\n",
    "flags['slowfast_alpha'] = 4\n",
    "flags['save_folder'] = './model_weights'\n",
    "flags['warmup_ratio'] = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackPathway(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // flags['slowfast_alpha']\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob('/data/competition/Another/Busan/Competition_1/행위/행위/*/*'))\n",
    "\n",
    "folder_path = []\n",
    "for i in paths:\n",
    "    if (i[-4:] not in \"json\") and (i[-3:] not in \"mp4\"):\n",
    "        folder_path.append(i)\n",
    "\n",
    "for j in folder_path:\n",
    "    try:\n",
    "        os.rmdir(j)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"빈 폴더 제거 전 :\", len(folder_path))\n",
    "\n",
    "paths = sorted(glob('/data/competition/Another/Busan/Competition_1/행위/행위/*/*'))\n",
    "\n",
    "folder_path = []\n",
    "for i in paths:\n",
    "    if (i[-4:] not in \"json\") and (i[-3:] not in \"mp4\"):\n",
    "        folder_path.append(i)\n",
    "        \n",
    "print(\"빈 폴더 제거 후 :\", len(folder_path))\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "test_paths = []\n",
    "for num, i in enumerate(range(len(folder_path))):\n",
    "    test_paths.append(folder_path[i])\n",
    "        \n",
    "print('test개수:', len(test_paths))\n",
    "df_test['file_path'] = test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, \n",
    "               df, \n",
    "               mode='test', \n",
    "               size=flags['size'], \n",
    "               num_frames=flags['num_frames'], \n",
    "               sampling_rate=flags['sampling_rate']):\n",
    "    self.df=df\n",
    "    self.mode=mode\n",
    "    self.size=size\n",
    "    self.num_frames=num_frames\n",
    "    self.sampling_rate=sampling_rate\n",
    "    self.slowfast_preproc=PackPathway()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    file_path=self.df['file_path'].iloc[idx]\n",
    "    img_path=sorted(glob(file_path + '/*.png'))\n",
    "    if self.mode=='train':\n",
    "        start=random.choice(np.arange(len(img_path)-self.sampling_rate*self.num_frames-1))\n",
    "    else:\n",
    "        start=0\n",
    "    imgs=torch.zeros(self.num_frames, 3, self.size, self.size)\n",
    "    for i, x in enumerate(range(start, start+self.sampling_rate*self.num_frames, self.sampling_rate)):\n",
    "        img = np.array(Image.open(img_path[x]))\n",
    "        imgs[i]=self.transform_func()(image=img)['image']\n",
    "    \n",
    "    imgs = self._pad(imgs)\n",
    "    frames=self.slowfast_preproc(imgs.permute(1, 0, 2, 3))\n",
    "    label = 0\n",
    "    if self.mode=='train':\n",
    "        if \"smoking\" in file_path:\n",
    "            label = 0\n",
    "        elif \"fishing\" in file_path:\n",
    "            label = 1\n",
    "        elif \"trash_dump\" in file_path:\n",
    "            label = 2\n",
    "        elif \"wall_over\" in file_path:\n",
    "            label = 3\n",
    "        elif \"damage_to_facilities\" in file_path:\n",
    "            label = 4\n",
    "        elif \"banner_action\" in file_path:\n",
    "            label = 5\n",
    "        elif \"fliers_action\" in file_path:\n",
    "            label = 5\n",
    "        elif \"tent_setup\" in file_path:\n",
    "            label = 6\n",
    "    else:\n",
    "        label=0\n",
    "    return frames, label\n",
    "\n",
    "  def transform_func(self):\n",
    "    return A.Compose([\n",
    "                      A.Resize(flags['size'],flags['size']), \n",
    "                      A.Normalize(mean=flags['mean'], std=flags['std']),\n",
    "                      ToTensorV2(p=1.0)\n",
    "                      ])\n",
    "    \n",
    "  def _pad(self, imgs):\n",
    "      if imgs.shape[0] < self.num_frames:\n",
    "          T, C, H, W = imgs.shape\n",
    "          pad = torch.zeros(self.num_frames-T, C, H, W)\n",
    "          imgs = torch.cat([imgs, pad], dim=0)\n",
    "      else:\n",
    "          imgs = imgs[:self.num_frames]\n",
    "\n",
    "      return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(df=df_test)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, num_workers=flags['num_worker'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.model=slowfast_16x8_r101_50_50(pretrained=True)\n",
    "        self.model.blocks[6].proj = nn.Linear(self.model.blocks[6].proj.in_features, 7, bias=True)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_func(model, test_dataloader):\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(test_dataloader)):\n",
    "            input = [x.to(device) for x in data[0]]\n",
    "            output = model(input)\n",
    "            logit = torch.softmax(output, dim=-1)\n",
    "            outputs.append(logit)\n",
    "\n",
    "    return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "custom_model = CustomModel(device=device)\n",
    "checkpoint = torch.load('./Final_Model/Model1_best-acc_20.bin', map_location='cpu')\n",
    "custom_model.load_state_dict(checkpoint)\n",
    "custom_model.eval()\n",
    "custom_model = custom_model.to(device)\n",
    "\n",
    "outputs1 = inference_func(custom_model1, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "custom_model = CustomModel(device=device)\n",
    "checkpoint = torch.load('./Final_Model/Model2_best-acc_20.bin', map_location='cpu')\n",
    "custom_model.load_state_dict(checkpoint)\n",
    "custom_model.eval()\n",
    "custom_model = custom_model.to(device)\n",
    "\n",
    "outputs2 = inference_func(custom_model1, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "custom_model = CustomModel(device=device)\n",
    "checkpoint = torch.load('./Final_Model/Model3_best-acc_20.bin', map_location='cpu')\n",
    "custom_model.load_state_dict(checkpoint)\n",
    "custom_model.eval()\n",
    "custom_model = custom_model.to(device)\n",
    "\n",
    "outputs3 = inference_func(custom_model1, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "custom_model = CustomModel(device=device)\n",
    "checkpoint = torch.load('./Final_Model/Model4_best-acc_20.bin', map_location='cpu')\n",
    "custom_model.load_state_dict(checkpoint)\n",
    "custom_model.eval()\n",
    "custom_model = custom_model.to(device)\n",
    "\n",
    "outputs4 = inference_func(custom_model1, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = (outputs1 + outputs2 + outputs3 + outputs4) / 4\n",
    "outputs = outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = sorted(glob('/data/competition/Another/Busan/Competition_1/행위/행위/*/*.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_label = []\n",
    "\n",
    "for i in tqdm(range(len(test_paths))):\n",
    "    mean = []\n",
    "    for j in range(outputs.shape[0]):\n",
    "        if test_paths[i].split(\".\")[0] in df_test[\"file_path\"].iloc[j]:\n",
    "            mean.append(outputs[j])\n",
    "            break\n",
    "    mean = np.array(mean)\n",
    "    mean_label = np.mean(mean, axis=0)\n",
    "    total_label.append(mean_label)\n",
    "total_label = np.array(total_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame()\n",
    "labels[\"file_path\"] = test_paths\n",
    "labels[\"label\"] = 0\n",
    "for i in range(labels.shape[0]):\n",
    "    labels[\"label\"].iloc[i] = total_label[i].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.to_csv(\"./final_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
